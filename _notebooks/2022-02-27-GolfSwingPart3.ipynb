{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Golf Swing Part III- Using pre-trained models and FiftyOne to find golf positions\n",
    "> Using Python and Coco to identify parts of the body and club during a golf swing \n",
    "\n",
    "- toc: true \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [Neural networks,FiftyOne, , Golf Swing, Python]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/header2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In a previous part [Part 1](https://thomashsimm.com/jupyter/2021/12/01/GolfPos1FastAI.html) a neural network model was used to find positions on the body during a golf swing. The model was not particularly succesful, perhaps due to the lack of data (specific to the golf swing) that was used to train the model on.\n",
    "\n",
    "This problem can be got around by using a model that has been pre-trained on human gestures. Several pre-trained models can be found here [Pre-trained models](https://voxel51.com/docs/fiftyone/user_guide/model_zoo/models.html). I tried a few and found the chose the model `keypoint-rcnn-resnet50-fpn-coco-torch` worked well with this data. [Link to model](https://voxel51.com/docs/fiftyone/user_guide/model_zoo/models.html#keypoint-rcnn-resnet50-fpn-coco-torch) and [Paper of model](https://arxiv.org/abs/1603.00502).\n",
    "\n",
    "\n",
    "More information on [fiftyOne](https://voxel51.com/).\n",
    "\n",
    "\n",
    "The input to the model is taken from [Part 2](https://thomashsimm.com/neural%20networks/pytourch/golf%20swing/python/2022/02/26/GolfSwingPart2.html) which separated a golf video into a series of images of the swing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "The code can be run on google colab here [COCO50_1](https://colab.research.google.com/drive/17Bb8n9D9_4aAuJlCf2yOQE08L7vjUtBm?usp=sharing) (works best on google chrome)\n",
    "\n",
    "## Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "!pip uninstall opencv_python_headless\n",
    "\n",
    "!pip install opencv-python-headless==4.5.4.60\n",
    "\n",
    "!pip install fiftyone\n",
    "\n",
    "import fiftyone as fo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upoad some images to the workspace\n",
    "\n",
    "Untar and create a dataset object from them\n",
    "\n",
    "And look at them\n",
    "\n",
    "The image files can be found here [GC2.tgz](https://drive.google.com/file/d/1FMOP3Lm-0Ed1SmuPYdcm6emUu-Jhv2CW/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "my_tar = tarfile.open('/content/GC2.tgz')\n",
    "my_tar.extractall('/content/my_folder') # specify which folder to extract to\n",
    "my_tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "name = \"my_folder\"\n",
    "dataset_dir = \"/content\"\n",
    "\n",
    "# Create the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=fo.types.ImageDirectory,\n",
    "    name=name,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/fiftyOneScreen.png)\n",
    "\n",
    "\n",
    "This screen is interative and allows us to look at the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trained model \n",
    "\n",
    "Apply the model to the dataset\n",
    "\n",
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = foz.load_zoo_model(\"keypoint-rcnn-resnet50-fpn-coco-torch\")\n",
    "\n",
    "# label_types=[\"classification\", \"classifications\", \"detections\", \"instances\", \"segmentations\", \"keypoints\", \"polylines\", \"polygons\", \"scalar\"],\n",
    "\n",
    "dataset.apply_model(model, label_field=\"predictions\",label_types='predictions_keypoints')\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/foo2.png)\n",
    "\n",
    "> youtube: https://youtu.be/dkxtOBWD7Vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from the model\n",
    "\n",
    "We might want to use the data from the model outside of fiftyOne. \n",
    "\n",
    "In the following I extract the data so that it can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "def plotPredOne(i):\n",
    "  import numpy as np\n",
    "\n",
    "  import matplotlib.pyplot as plt\n",
    "  import matplotlib.image as mpimg\n",
    "\n",
    "  img = mpimg.imread(i['filepath'])\n",
    "\n",
    "  #need to take account of more than one person in image\n",
    "  points1 = np.array(i['predictions_keypoints']['keypoints'][0]['points'])\n",
    "  adjPts = np.shape(img)[0]\n",
    "  box1 = np.array(i['predictions_detections']['detections'][0]['bounding_box']) \n",
    "  box1=box1*adjPts\n",
    "  # Bboxes are in [top-left-x, top-left-y, width, height] format\n",
    "  box2=np.array([ \n",
    "      [box1[0], box1[1]],\n",
    "      [box1[0] +box1[2] ,box1[1] ],\n",
    "      [box1[0] +box1[2] ,box1[1] +box1[3]] ,\n",
    "      [box1[0]  ,box1[1] +box1[3]],\n",
    "      [box1[0], box1[1]]\n",
    "      ])\n",
    " \n",
    "  plt.figure()\n",
    "  plt.imshow(img)\n",
    "\n",
    "  plt.plot(points1[:,0]*adjPts,points1[:,1]*adjPts, '+k',markersize=10,linewidth=3)\n",
    "  plt.plot(box2[:,0],box2[:,1], '--og',markersize=10,linewidth=3)\n",
    "\n",
    "    #back of body\n",
    "  v=[4,6,12,14,16]\n",
    "  plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-k<',markersize=10,linewidth=2)\n",
    "\n",
    "  #front of body\n",
    "  v=[0,5,11,13,15]\n",
    "  plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-w>',markersize=10,linewidth=2)\n",
    "\n",
    "  vects = np.array([[ 5,6],#shoulders also 4?\n",
    "         [11,12], #hips\n",
    "         [13,14], #knees\n",
    "         [15,16],#heels\n",
    "         [7,8],#elbows\n",
    "         [9,10],#hands\n",
    "         ]) \n",
    "  mak='gcyrmb'\n",
    "  for iv,v in enumerate(vects):\n",
    "    plt.plot(points1[v,0]*adjPts,points1[v,1]*adjPts, '-'+mak[iv],markersize=10,linewidth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "for iii,i in enumerate(dataset):\n",
    "  \n",
    "  plotPredOne(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](ghtop_images/foo3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
